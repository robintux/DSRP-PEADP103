{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Clase_26Sept_Pruebas_AB.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPRgbpDD/k60nwO0lW/tTOj"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"RzNFdwsDTpc8"},"source":["# Prueba o test A/B \n","\n","Deacuerdo  a la [wikipedia](https://es.wikipedia.org/wiki/Prueba_A/B) : \n","\n","_El término test A/B se utiliza en el ámbito del Marketing Digital y la Analítica web para describir experimentos aleatorios con dos variantes, A y B, siendo una la de control y la otra la variante. Otra forma de referirse generalmente a los test A/B es con el término split test, aunque este último método se aplica cuando se realizan experimentos con más de dos variantes._\n","\n","\n","En este notebook desarrollaremos (como a lo largo de las clases) el proceso de análisis de un experimento/prueba/test A/B, desde formular una hipótesis, probarla y finalmente interpretar los resultados. Para que esto sea facil de replicar , usaremos un conjunto de datos de Kaggle que contiene los resultados de una prueba A/B en lo que parecen ser 2 diseños diferentes de una página de sitio web (_old_page_ vs. _new_page_).\n","\n","Esto es lo que haremos: \n","  * Diseñando nuestro experimento \n","  * Recopilar y preparar los datos \n","  * Visualizando los resultados \n","  * Probando la hipótesis \n","  * Sacar conclusiones\n","\n","Para hacerlo un poco más realista, aquí hay un escenario potencial para nuestro estudio:\n","\n","> Imaginemos que trabaja en el equipo de productos de una empresa de comercio electrónico online de tamaño medio. El diseñador de UX trabajó muy duro en una nueva versión de la página del producto, con la esperanza de que conduzca a una mayor tasa de conversión. El gerente de producto (PM) le dijo que la tasa de conversión actual es de aproximadamente un 13% en promedio durante todo el año, y que el equipo estaría contento con un aumento del 2%, lo que significa que el nuevo diseño se considerará un éxito si aumenta la tasa de conversión al 15%.\n","\n","Antes de implementar el cambio, el equipo se sentiría más cómodo probándolo en una pequeña cantidad de usuarios para ver cómo funciona, por lo que sugiere ejecutar una prueba A / B en un subconjunto de usuarios de su base de usuarios.\n","\n","## 1.Diseñando nuestro experimento\n","Empezemos diseñando nuestro experimento :\n","\n","### Formular una hipótesis\n","\n","Lo primero es lo primero, queremos asegurarnos de formular una hipótesis al comienzo de nuestro proyecto. Esto asegurará que nuestra interpretación de los resultados sea correcta y rigurosa.\n","\n","Dado que no sabemos si el nuevo diseño funcionará mejor o peor (¿o igual?) Que nuestro diseño actual, elegiremos una prueba de dos colas (*two-tailed test*):\n","\n","$$H_0 :p = p_0$$\n","\n","$$H_a : p \\neq p_0$$\n","\n","donde $p$ y $p_0$ representan la tasa de conversión del diseño nuevo y antiguo, respectivamente. También estableceremos un nivel de confianza del 95%:\n","\n","$$\\alpha = 0.05$$\n","\n","El valor $\\alpha$ es un umbral que establecemos, por el cual decimos “si la probabilidad de observar un resultado como extremo o mayor (valor p) es menor que $\\alpha$, entonces rechazamos la hipótesis nula”. Dado que nuestro $\\alpha$ = 0.05 (que indica un 5% de probabilidad), nuestra confianza (1 - $\\alpha$) es del 95%.\n","\n","No se preocupe si no está familiarizado con lo anterior, todo esto realmente significa que cualquiera que sea la tasa de conversión que observemos para nuestro nuevo diseño en nuestra prueba, queremos tener un 95% de confianza en que es estadísticamente diferente de la tasa de conversión de nuestro antiguo diseño, antes de que decidamos rechazar la hipótesis nula $H_0$.\n","\n","### Elegir las variables\n","\n","Para nuestra prueba, necesitaremos dos grupos:\n","\n","  * Un grupo de control: se les mostrará el diseño anterior\n","\n","  * Un grupo de prueba (tratamiento o experimental): se les mostrará el nuevo diseño\n","\n","Esta será nuestra Variable Independiente. La razón por la que tenemos dos grupos, a pesar de que conocemos la tasa de conversión inicial, es que queremos controlar otras variables que podrían tener un efecto en nuestros resultados, como la estacionalidad: al tener un grupo de control, podemos comparar directamente sus resultados con el tratamiento. grupo, porque la única diferencia sistemática entre los grupos es el diseño de la página del producto, y por lo tanto podemos atribuir cualquier diferencia en los resultados a los diseños.\n","\n","Para nuestra Variable dependiente (es decir, lo que estamos tratando de medir), estamos interesados ​​en capturar la tasa de conversión. Una forma en que podemos codificar esto es mediante cada sesión de usuario con una variable binaria:\n","\n","  * 0: el usuario no compró el producto durante esta sesión de usuario\n","\n","  * 1 - El usuario compró el producto durante esta sesión de usuario\n","\n","De esta manera, podemos calcular fácilmente la media de cada grupo para obtener la tasa de conversión de cada diseño.\n","\n","### Elegir un tamaño de muestra\n","Es importante tener en cuenta que, dado que no probaremos toda la base de usuarios (nuestra población), las tasas de conversión que obtendremos serán, inevitablemente, solo estimaciones de las tasas reales.\n","\n","El número de personas (o sesiones de usuario) que decidamos capturar en cada grupo tendrá un efecto en la precisión de nuestras tasas de conversión estimadas: cuanto mayor sea el tamaño de la muestra, más precisas serán nuestras estimaciones (es decir, cuanto menores sean nuestros intervalos de confianza), mayor es la posibilidad de detectar una diferencia en los dos grupos, si está presente.\n","\n","Por otro lado, cuanto más grande es nuestra muestra, más caro (y poco práctico) se vuelve nuestro estudio.\n","\n","Entonces, **¿cuántas personas deberíamos tener en cada grupo?**\n","\n","El tamaño de la muestra que necesitamos se estima mediante algo llamado [análisis de potencia](https://research.usu.edu//irb/wp-content/uploads/sites/12/2015/08/A_Researchers_Guide_to_Power_Analysis_USU.pdf), y depende de algunos factores:\n","\n","  * **Potencia de la prueba (1 - β)**: representa la probabilidad de encontrar una diferencia estadística entre los grupos de nuestra prueba cuando existe una diferencia. Esto generalmente se establece en 0.8 por convención (mas informacion en la [wiki](https://en.wikipedia.org/wiki/Power_of_a_test))\n","\n","  * **Valor alfa (α)**: el valor crítico que establecimos anteriormente en 0.05\n","\n","  * **Tamaño del efecto**: qué tan grande es la diferencia que esperamos que haya entre las tasas de conversión\n","\n","Dado que nuestro equipo estaría contento con una diferencia del 2%, podemos usar el 13% y el 15% para calcular el tamaño del efecto que esperamos.\n","\n","Afortunadamente,y como ya lo hemos hecho en notebooks pasados,  Python se encarga de todos estos cálculos por nosotros:"]},{"cell_type":"code","metadata":{"id":"YSZZPsdEKTk4"},"source":["# Packages imports\n","import numpy as np\n","import pandas as pd\n","import scipy.stats as stats\n","import statsmodels.stats.api as sms\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from math import ceil\n","\n","%matplotlib inline\n","\n","# Some plot styling preferences\n","plt.style.use('seaborn-whitegrid')\n","font = {'family' : 'Helvetica',\n","        'weight' : 'bold',\n","        'size'   : 14}\n","\n","mpl.rc('font', **font)\n","effect_size = sms.proportion_effectsize(0.13, 0.15)    # Calculating effect size based on our expected rates\n","\n","required_n = sms.NormalIndPower().solve_power(\n","    effect_size, \n","    power=0.8, \n","    alpha=0.05, \n","    ratio=1\n","    )                                                  # Calculating sample size needed\n","\n","required_n = ceil(required_n)                          # Rounding up to next whole number                          \n","\n","print(required_n)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XZWS6HCfVyiO"},"source":["Necesitaríamos al menos **4720 observaciones para cada grupo**.\n","\n","Habiendo establecido el parámetro de potencia en 0.8 en la práctica significa que si existe una diferencia real en la tasa de conversión entre nuestros diseños, asumiendo que la diferencia es la que estimamos (13% vs 15%), tenemos alrededor del 80% de posibilidades de detectarla. como estadísticamente significativo en nuestra prueba con el tamaño de la muestra que calculamos.\n","\n","## 2.Recopilar y preparar los datos\n","Entonces, ahora que tenemos nuestro tamaño de muestra requerido, necesitamos recopilar los datos. Por lo general, en este punto, trabajaría con su equipo para configurar el experimento, probablemente con la ayuda del equipo de ingeniería, y se aseguraría de recopilar suficientes datos según el tamaño de muestra necesario.\n","\n","Sin embargo, usaremos un conjunto de datos que encontramos en línea, para simular esta situación:\n","\n","  > Descarga el conjunto de datos de Kaggle\n","\n","  >  Almacenar la data en una variable de tipo [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)\n","\n","  > Verifique y limpie los datos según sea necesario\n","\n","  > Muestra aleatoria de $n = 4720$ filas del DataFrame para cada grupo\n","\n","* _Nota_: Normalmente, no necesitaríamos realizar el paso 4, esto es solo por el ejercicio\n","\n","Nuestro siguiente paso es cargar los datos en nuestro notebook para empezar con el analisis :\n"]},{"cell_type":"code","metadata":{"id":"SSvDhMdIKr6P"},"source":["# 1era forma : descargamos los datos de kaggle y los subimos a nuestro notebook :\n","# descargamos la data :\n","# https://www.kaggle.com/zhangluyuan/ab-testing?select=ab_data.csv\n","# Luego cargamos estos datos en google colab\n","\n","from google.colab import files\n","\n","uploaded = files.upload() \n","\n","# La otra opcion es subirlo al repo de datos de robintux y desde ahi cargar la data."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7S1kCAa8MnV1"},"source":["# 1era forma\n","df = pd.read_csv('ab_data.csv')\n","\n","# 2da forma\n","# df= pd.read_csv(\"https://raw.githubusercontent.com/robintux/Datasets4StackOverFlowQuestions/master/ab_data.csv\")\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9JBI9pvFMuUr"},"source":["df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"USgTGOsIMwUf"},"source":["# Para asegurarse de que todo el grupo de control esté viendo la página anterior y viceversa\n","pd.crosstab(df['group'], df['landing_page'])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MtdNXef7wGfK"},"source":["Hay 294478 filas en el DataFrame, cada una de las cuales representa una sesión de usuario, así como 5 columnas:\n","\n","> $user\\_id$ - El ID del usuario de cada sesion\n","\n","> $timestamp$ - Informacion temporal de la sesion.\n","\n","> $group$ - A qué grupo se asignó el usuario para esa sesión\n","(_control_, _prueba_)\n","\n","> $landing\\_page$ - Qué diseño vio cada usuario en esa sesión\n","(_old_page_, _new_page_)\n","\n","> converted - Si la sesión terminó en una conversión o no\n","(variable binaria, $0$ = _no se convirtio_ , $1$= Se convirtio )\n","\n","De hecho, solo usaremos las variables $group$ y $converted$ para nuestro analisis análisis.\n","\n","Antes de continuar y muestrear los datos para obtener nuestro subconjunto, asegurémonos de que no haya usuarios que hayan sido muestreados varias veces."]},{"cell_type":"code","metadata":{"id":"hBoYpljAM3iw"},"source":["session_counts = df['user_id'].value_counts(ascending=False)\n","multi_users = session_counts[session_counts > 1].count()\n","\n","print(f'Hay {multi_users} usuarios que aparecen varias veces en el conjunto de datos')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6AP641LD0XT5"},"source":["De hecho, hay 3894 usuarios que aparecen más de una vez. Dado que el número es bastante bajo, continuaremos y los eliminaremos del DataFrame para evitar muestrear a los mismos usuarios dos veces.\n"]},{"cell_type":"code","metadata":{"id":"3NSzzFjwM6A1"},"source":["users_to_drop = session_counts[session_counts > 1].index\n","\n","df = df[~df['user_id'].isin(users_to_drop)]\n","print(f'Despues de limpiar esos usuarios que aparecen multiples veces \\nEl dataframe ahora tiene {df.shape[0]} filas')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zmK7ns7S0dMj"},"source":["### Muestreo\n","\n","Ahora que nuestro DataFrame es agradable y limpio, podemos continuar y muestrear n = 4720 entradas para cada uno de los grupos. Podemos usar el método DataFrame.sample () de pandas para hacer esto, que realizará un muestreo aleatorio simple para nosotros.\n","\n","Nota: Configuraremos random_state = 22 para que los resultados sean reproducibles si desea seguir en su propio Notebook: simplemente use random_state = 22 en su función y debería obtener la misma muestra.\n","\n"]},{"cell_type":"code","metadata":{"id":"t-jwkOB3M8mr"},"source":["control_sample = df[df['group'] == 'control'].sample(n=required_n, random_state=22)\n","treatment_sample = df[df['group'] == 'treatment'].sample(n=required_n, random_state=22)\n","\n","ab_test = pd.concat([control_sample, treatment_sample], axis=0)\n","ab_test.reset_index(drop=True, inplace=True)\n","ab_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1S8IJyg5NANi"},"source":["ab_test.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-AxXVJBQNDzX"},"source":["ab_test['group'].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e1_cuZ-K06JW"},"source":["Genial, parece que todo salió según lo planeado y ahora estamos listos para analizar nuestros resultados.\n","\n","\n","## 3.Visualizando los resultados\n","Lo primero que podemos hacer es calcular algunas estadísticas básicas para tener una idea de cómo se ven nuestras muestras.\n","\n"]},{"cell_type":"code","metadata":{"id":"IF0LtKi-NGkg"},"source":["conversion_rates = ab_test.groupby('group')['converted']\n","\n","std_p = lambda x: np.std(x, ddof=0)              # Std. deviation of the proportion\n","se_p = lambda x: stats.sem(x, ddof=0)            # Std. error of the proportion (std / sqrt(n))\n","\n","conversion_rates = conversion_rates.agg([np.mean, std_p, se_p])\n","conversion_rates.columns = ['conversion_rate', 'std_deviation', 'std_error']\n","\n","\n","conversion_rates.style.format('{:.3f}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OxSnuqpV1Pi7"},"source":["A juzgar por las estadísticas anteriores, parece que nuestros dos diseños funcionaron de manera muy similar, con nuestro nuevo diseño un poco mejor, aprox. 12,3% frente a 12,6% de tasa de conversión.\n","\n","Graficar los datos facilitará la comprensión de estos resultados:\n","\n"]},{"cell_type":"code","metadata":{"id":"HUOpucsCNIsj"},"source":["plt.figure(figsize=(8,6))\n","\n","sns.barplot(x=ab_test['group'], y=ab_test['converted'], ci=False)\n","\n","plt.ylim(0, 0.17)\n","plt.title('Ratio de conversion porgrupo', pad=20)\n","plt.xlabel('Grupos', labelpad=15)\n","plt.ylabel('Converted (proporcion)', labelpad=15);\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MPqVFANs1oDU"},"source":["Las tasas de conversión de nuestros grupos están muy cerca. También tenga en cuenta que la tasa de conversión del grupo de control es menor de lo que hubiéramos esperado dado lo que sabíamos sobre nuestro promedio. tasa de conversión (12,3% frente a 13%). Esto demuestra que existe cierta variación en los resultados cuando se toman muestras de una población.\n","\n","Entonces… __el valor del grupo de tratamiento es mayor. ¿Es esta diferencia estadísticamente significativa?__\n","\n","## 4.Prueba de la hipótesis\n","\n","El último paso de nuestro análisis es probar nuestra hipótesis. Dado que tenemos una muestra muy grande, podemos usar la aproximación normal para calcular nuestro valor p (es decir, prueba z).\n","\n","Una vez más, Python facilita todos los cálculos. Podemos usar el módulo statsmodels.stats.proportion para obtener el valor p y los intervalos de confianza:\n","\n"]},{"cell_type":"code","metadata":{"id":"OstSped5TQeF"},"source":["from statsmodels.stats.proportion import proportions_ztest, proportion_confint\n","control_results = ab_test[ab_test['group'] == 'control']['converted']\n","treatment_results = ab_test[ab_test['group'] == 'treatment']['converted']\n","n_con = control_results.count()\n","n_treat = treatment_results.count()\n","successes = [control_results.sum(), treatment_results.sum()]\n","nobs = [n_con, n_treat]\n","\n","z_stat, pval = proportions_ztest(successes, nobs=nobs)\n","(lower_con, lower_treat), (upper_con, upper_treat) = proportion_confint(successes, nobs=nobs, alpha=0.05)\n","\n","print(f'z statistic: {z_stat:.2f}')\n","print(f'p-value: {pval:.3f}')\n","print(f'ci 95% for control group: [{lower_con:.3f}, {upper_con:.3f}]')\n","print(f'ci 95% for treatment group: [{lower_treat:.3f}, {upper_treat:.3f}]')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TMdbYj5NNhPt"},"source":["## 5.Sacar conclusiones\n","\n","Dado que nuestro valor p = 0,732 está muy por encima de nuestro umbral α = 0,05, no podemos rechazar la hipótesis nula Hₒ, lo que significa que nuestro nuevo diseño no tuvo un rendimiento significativamente diferente (y mucho menos mejor) que el anterior.\n","\n","Además, si observamos el intervalo de confianza para el grupo de tratamiento ([0.116, 0.135] o 11.6-13.5%) notamos que:\n","\n","  > Incluye nuestro valor de referencia del 13% de tasa de conversión.\n","\n","  > No incluye nuestro valor objetivo del 15% (el aumento del 2% al que aspiramos)\n","\n","Lo que esto significa es que es más probable que la tasa de conversión real del nuevo diseño sea similar a nuestra línea de base, en lugar del objetivo del 15% que esperábamos. Esta es una prueba más de que no es probable que nuestro nuevo diseño sea una mejora con respecto a nuestro diseño anterior, y que, lamentablemente, ¡volvemos a la mesa de dibujo!\n"]}]}