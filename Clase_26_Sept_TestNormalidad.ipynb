{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TestNormalidad.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNfVfqRtgmfZHHnMSy7kU7p"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"uEwoZQTzQrtf"},"source":["# Test de Normalidad\n","\n","Entonces, tiene un conjunto de datos y está a punto de ejecutar algunas pruebas en él, pero primero, debe verificar la normalidad.\n","\n","Piense en esta pregunta, \"Dados mis datos ... si hay una desviación de la normalidad, ¿habrá un impacto material en mis resultados?\"\n","\n","Al hacerlo, hay tres pruebas que quizás desee considerar:\n","\n","  * La prueba de Shapiro-Wilk;\n","  * La prueba de Anderson-Darling y;\n","  * La prueba de Kolmogorov-Smirnov.\n","\n","Además como todo entra por los ojos, hay algunas medidas visuales a implementar:\n","\n","  1. Box Plots\n","  2. QQ Plots\n","\n","---\n","Entonces, ¿por qué hacer todas estas pruebas en primer lugar? Voy a citar directamente [de esta publicación](https://stats.stackexchange.com/questions/2492/is-normality-testing-essentially-useless) con validación cruzada, que desglosa cómo pensar sobre las pruebas de normalidad.\n","\n","> Es un hecho (un poco explícito) que las pruebas de normalidad formales siempre rechazan los enormes tamaños de muestra con los que trabajamos hoy. Incluso es fácil demostrar que cuando n aumenta, incluso la desviación más pequeña de la normalidad perfecta conducirá a un resultado significativo. Y como cada conjunto de datos tiene cierto grado de aleatoriedad, ningún conjunto de datos será una muestra perfectamente distribuida normalmente. Pero en las estadísticas aplicadas, la cuestión no es si los datos / residuos (en el caso de unaregresion) ... son perfectamente normales, sino lo suficientemente normales para que se mantengan las suposiciones.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kRArN-ctMBJ0"},"source":["## 1.Shapiro-Wilk\n","\n","Las pruebas de Shapiro-Wilk si una muestra aleatoria proviene de una distribución normal. La hipótesis nula de la prueba es que los datos se distribuyen normalmente. Si el valor p devuelto es menor que 05, entonces se rechaza la hipótesis nula y hay evidencia de que los datos no provienen de una población distribuida normalmente.\n","\n","Sin embargo, es completamente posible que para p> 0.05 y los datos no provengan de una población normal. El rechazo podría deberse a que el tamaño de la muestra es demasiado pequeño para detectar la no normalidad. Por lo tanto, tenga esto en cuenta al interpretar los resultados.\n","\n","Además, el método stats.shapiro arrojará una advertencia en las muestras de tamaño> 5000. Por lo tanto, para conjuntos de datos más grandes que ese, es posible que desee elegir otra prueba de normalidad.\n","\n","Como podemos ver en los ejemplos siguientes, tenemos muestras aleatorias de una variable aleatoria normal donde n = [10, 50, 100, 1000] y la prueba de Shapiro-Wilk puede rechazar alguna de ellas. Por lo tanto, es posible que tengamos que usar alguna medida adicional para ver si la hipótesis nula para de alguna de ellas debería/podria ser rechazada."]},{"cell_type":"code","metadata":{"id":"zdzHY1dvQqJy"},"source":["from scipy import stats\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Set style\n","plt.style.use('ggplot')\n","\n","# Start with shaprio\n","\n","# mean = loc, scale = sd, size = n\n","x_10 = stats.norm.rvs(loc=5, scale=3, size=10)\n","x_50 = stats.norm.rvs(loc=5, scale=3, size=50)\n","x_100 = stats.norm.rvs(loc=5, scale=3, size=100)\n","x_1000 = stats.norm.rvs(loc=5, scale=3, size=1000)\n","\n","def four_plots():\n","    plt.subplot(2, 2, 1)\n","    plt.hist(x_10)\n","    plt.title('Histograma para: x_10')\n","    plt.subplot(2, 2, 2)\n","    plt.hist(x_50)\n","    plt.title('Histograma para: x_50')\n","    plt.subplot(2, 2, 3)\n","    plt.hist(x_100)\n","    plt.title('Histograma para: x_100')\n","    plt.subplot(2, 2, 4)\n","    plt.hist(x_1000)\n","    plt.title('Histograma para: x_1000')\n","    plt.suptitle('Muestreo de Variables Aleatorias Normales: x_N', fontsize=14)\n","    plt.show()\n","    \n","\n","plt.figure(figsize=(18,10))\n","four_plots()\n","\n","# Perform test\n","print(stats.shapiro(x_10))\n","print(stats.shapiro(x_50))\n","print(stats.shapiro(x_100))\n","print(stats.shapiro(x_1000))\n","\n","def accept_reject(shaprio):\n","    if shaprio[1] > .05 :\n","        output  = \"No rechaces la hipótesis de la normalidad\"\n","    else:\n","        output = \"Rechazar la hipótesis de normalidad\"\n","    return output\n","\n","print(\"Para x_10: \", accept_reject(stats.shapiro(x_10)))\n","print(\"Para x_50: \",  accept_reject(stats.shapiro(x_50)))\n","print(\"Para x_100: \",  accept_reject(stats.shapiro(x_100)))\n","print(\"Para x_1000: \",  accept_reject(stats.shapiro(x_1000)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"45pzzGKe8fNL"},"source":["Veamos el primer método de visualización, el diagrama de caja, para ver si podemos respaldar los resultados de esta prueba. Estas gráficas no deben usarse únicamente para detectar la normalidad, sino para buscar simetría, asimetría y valores atípicos para dar indicaciones de no normalidad. En general, los gráficos de diagrama de caja no son muy informativos para comprender la normalidad y se han incluido para completar estenotebook de la clase."]},{"cell_type":"code","metadata":{"id":"2mydkRVKXONg"},"source":["# hechemos una vistazo a los box plots\n","def four_box():\n","    plt.subplot(2, 2, 1)\n","    plt.boxplot(x_10)\n","    plt.title('Boxplot para: x_10')\n","    plt.subplot(2, 2, 2)\n","    plt.boxplot(x_50)\n","    plt.title('Boxplot para: x_50')\n","    plt.subplot(2, 2, 3)\n","    plt.boxplot(x_100)\n","    plt.title('Boxplot para: x_100')\n","    plt.subplot(2, 2, 4)\n","    plt.boxplot(x_1000)\n","    plt.title('Boxplot para: x_1000')\n","    plt.suptitle('Variables normales muestreadas aleatoriamente: x_N', fontsize=14)\n","    plt.show()\n","    \n","\n","plt.figure(figsize=(18,10))\n","four_box()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wYIabjLM8_eQ"},"source":["Analisis de los boxplots : \n","\n","Valores Atipicos ? \n","Simetria ? \n","\n","¿Qué hay que mirar el gráfico QQ?\n","\n","El nombre formal es la gráfica de cuantiles-cuantiles (QQ) y determina si dos conjuntos de datos diferentes, el que usted proporciona y un conjunto distribuido normalmente, provienen de una población con distribuciones comunes.\n","\n","Un cuantil es el porcentaje de puntos por debajo del valor dado. Si las dos distribuciones que se comparan son de una distribución común, los puntos de la grafica QQ aproximadamente se encontrarán en una línea, pero no necesariamente en la línea y = x. Debido a que las muestras tienen una media de 4 y una sd de 3, se usó el parámetro _line = 's'_ para nuestro gráfico. La _s_ es una línea estandarizada para el orden esperado de las estadísticas, escalado por la desviación estándar de nuestras muestras con la media agregada. Básicamente, coloca la línea donde debe estar para comparar nuestros datos con lo que se esperaría de una distribución normal."]},{"cell_type":"code","metadata":{"id":"Moi1GBncXT2c"},"source":["# QQ PLOT\n","import statsmodels.api as sm\n","import pylab\n","\n","sm.qqplot(x_10, loc = 4, scale = 3, line='s')\n","sm.qqplot(x_50, loc = 4, scale = 3, line='s')\n","sm.qqplot(x_100, loc = 4, scale = 3, line='s')\n","sm.qqplot(x_1000, loc = 4, scale = 3, line='s')\n","pylab.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W9XAS29E-FJ5"},"source":["La gráfica QQ es una visualización mucho mejor de nuestros datos, brindándonos más certeza sobre la normalidad. A partir del gráfico QQ para x_50 podemos estar más seguros de que nuestros datos son normales, en lugar de depender simplemente del valor p de la prueba de Shapiro-Wilk o el gráfico de caja.\n","\n","Solo para ver cómo se vería un gráfico QQ en datos que no se distribuyen normalmente, generemos un gráfico para una distribución bimodal.\n"]},{"cell_type":"code","metadata":{"id":"uNjoKlqr0dOz"},"source":["# Creamos un conjunto de datos bimodal\n","N = 10000\n","x_bimodal = np.concatenate((np.random.normal(-1, 1, int(0.1 * N)),\n","                    np.random.normal(5, 1, int(0.4 * N))))[:, np.newaxis]\n","# Ahora lo graficamos\n","res = plt.hist(x_bimodal, bins=100)\n","sm.qqplot(x_bimodal[:,0], line='s')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0bL_mbWN-vDC"},"source":["Podemos ver claramente de la gráfica QQ, que podemos rechazar cualquier noción de que x_bimodal se recopiló de una muestra normal. Como referencia, aquí hay una visualización de gráficos QQ con diferentes tipos de datos.\n","\n","![](https://miro.medium.com/max/475/0*EfnZXzw3KDz-HN19.png)\n","\n","La prueba de Shapiro-Wilk es popular para determinar la normalidad y generalmente funciona muy bien, pero no es universalmente mejor. Debe conocer las limitaciones mencionadas anteriormente y utilizar métodos adicionales para verificar sus resultados.\n","\n","## 2.Kolmogorov-Smirnov\n","Las pruebas de Kolmogorov-Smirnov si una distribución muestral se ajusta a una función de distribución acumulada (CDF) de una distribución referenciada. O, si el CDF entre dos muestras diferentes encaja entre sí. Estos no son necesariamente solo para distribuciones normales, pero los usaremos en nuestro ejemplo. Básicamente, estamos probando los datos de la muestra con otra muestra, para comparar sus distribuciones en busca de similitudes.\n","\n","Similar a Shapiro-Wilk, nuestra hipótesis nula para nuestra muestra es que la distribución es idéntica a la otra distribución con la que la estamos probando. Si p-value < 0.05 podemos rechazar la hipotesis nula y concluir que nuestra distribución muestral no es idéntica a una distribución normal.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"ThfnFrus0hub"},"source":["# Prueba de KS contra una distribución normal con media = 5 y sd = 3\n","print(stats.kstest(x_10, 'norm', args=(5, 3)))\n","print(stats.kstest(x_50, 'norm', args=(5, 3)))\n","print(stats.kstest(x_100, 'norm', args=(5, 3)))\n","print(stats.kstest(x_1000, 'norm', args=(5, 3)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TlgqLufe_tgz"},"source":["Parece que nuestros resultados nos dicen que no rechacemos la hipótesis nula para todo x_N, sin embargo, x_50 está justo en la cerca. Probablemente se deba a que x_50 no tiene suficientes datos para juzgar con precisión si procede de la misma distribución. Veamos cómo se vería gráficamente al comparar los CDF de la muestra con una variable normal muestreada con la misma desviación estándar y media.\n","\n","Ahora tiene más sentido que el valor p estuviera tan cerca de la región de rechazo, dada la gran desviación de las dos líneas CDF. Veamos el mismo gráfico CDF, excepto x_100.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"U6rAI9BM04mp"},"source":["def ks_plot_norm(data):\n","    length = len(data)\n","    plt.figure(figsize=(12, 7))\n","    plt.plot(np.sort(x_100), np.linspace(0, 1, len(x_100), endpoint=False))\n","    plt.plot(np.sort(stats.norm.rvs(loc=5, scale=3, size=100)), np.linspace(0, 1, len(x_100), endpoint=False))\n","    plt.legend('top right')\n","    plt.legend(['Data', 'Valores teoricos'])\n","    plt.title('Comparando Funciones de distribucion paral a prueba de KS')\n","    \n","ks_plot_norm(x_100)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PW9l4qNVrx4V"},"source":["Se ve mucho mejor ahora que la prueba KS tiene más datos para comparar, lo que tiene sentido ya que x_50 tiene menos muestras que x_100.\n","\n","Realicemos la misma prueba, esta vez con variables uniformes contrastadas con una distribución uniforme. No deberíamos ver rechazada la hipótesis nula.\n"]},{"cell_type":"code","metadata":{"id":"LJ34da8p1FaQ"},"source":["# probemos con una distribucion uniforme\n","x_uni = np.random.rand(1000)\n","stats.kstest(x_uni, lambda x: x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8_Uy1CMvsAZq"},"source":["¿Cómo se vería nuestro gráfico CDF de prueba KS si comparamos nuestro x_100 con los datos bimodales que generamos anteriormente? Deberíamos esperar grandes desviaciones de cada CDF y una prueba KS que rechaza la hipótesis nula.\n"]},{"cell_type":"code","metadata":{"id":"dJRzueci1Hz4"},"source":["# generamos una binomial\n","N = 100\n","x_bimodal_100 = np.concatenate((np.random.normal(-1, 1, int(0.1 * N)),\n","                    np.random.normal(5, 1, int(0.4 * N))))[:, np.newaxis]\n","# Plot the CDFs\n","def ks_plot_comp(data_1, data_2):\n","    '''\n","    Los datos ingresados deben ser del mismo tamaño.\n","    '''\n","    length = len(data_1)\n","    plt.figure(figsize=(12, 7))\n","    plt.plot(np.sort(data_1), np.linspace(0, 1, len(data_1), endpoint=False))\n","    plt.plot(np.sort(data_2), np.linspace(0, 1, len(data_2), endpoint=False))\n","    plt.legend('top right')\n","    plt.legend(['Data_1', 'Data_2'])\n","    plt.title('Comparamos dos  funciones de distribucion para la prueba de KS')\n","    \n","ks_plot_comp(x_100, x_bimodal_100[:,0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D82HWDMXsOeK"},"source":["Podemos ver que x_100 y x_bimodal_100 divergen considerablemente, por lo que la prueba de Kolmogorov-Smirnov proporciona un valor p que rechaza la hipótesis nula.\n"]},{"cell_type":"code","metadata":{"id":"LJfYumpf1Ljm"},"source":["# Comprueba si las distribuciones son iguales\n","stats.ks_2samp(x_100, x_bimodal_100[:,0])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2W6eCzeDsSHI"},"source":["## 3.Anderson-Darling\n","\n","Anderson-Darling prueba si los datos provienen de una distribución particular. La hipótesis nula, similar a las dos pruebas anteriores, es que la muestra proviene de una población que sigue una distribución particular. En este caso, probaremos si nuestros datos provienen de una distribución normal.\n","\n","La ventaja aquí es que esta es una prueba más sensible para verificar diferentes distribuciones. Sin embargo, los valores críticos deben calcularse para cada distribución, por lo que podría ser más complicado determinar los valores de las diferentes distribuciones. El paquete python permite que estas distribuciones diferentes (normal, exponencial, logística, etc.) se prueben con el parámetro dist.\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"-j0oDCp45u9s"},"source":["# Prueba AD\n","anderson_results_10 = stats.anderson(x_10, dist='norm')\n","anderson_results_50 = stats.anderson(x_50, dist='norm')\n","anderson_results_100 = stats.anderson(x_100, dist='norm')\n","anderson_results_1000 = stats.anderson(x_1000, dist='norm')\n","print(anderson_results_10)\n","print(anderson_results_50)\n","print(anderson_results_100)\n","print(anderson_results_1000)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ArBMBHdutXpA"},"source":["Los resultados nos dan los valores p para varios niveles de significancia [15. , 10., 5., 2.5, 1.] por lo que si está trabajando con límites fuera de .05, también puede ver esos resultados.\n","\n","Aquí nuestro valor p para .05 está fuera de la región de rechazo de 0.784, lo que significa que no podemos rechazar la hipótesis nula de que nuestros datos provienen de una distribución normal. De nuevo lo que hubiéramos esperado\n","\n","---\n","\n","Y ahí lo tienes, tres pruebas diferentes y algunas medidas gráficas para ver si tus datos se distribuyen normalmente. Además, algunos métodos para ver si sus datos se distribuyen de diferentes formas.\n","\n","La principal lección de este notebook es comprender qué significan sus pruebas de normalidad, por qué implementarlas y cuándo ser escéptico con ellas. No existe una mejor prueba de normalidad y es bueno sospechar de los resultados hasta que pueda verificarlos mediante medidas adicionales."]}]}