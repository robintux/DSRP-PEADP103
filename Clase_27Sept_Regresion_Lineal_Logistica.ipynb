{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Clase_27Sept_Regresion_Lineal_Logistica.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNMFQTHxDclAifCqw6ppT0B"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Ri0sPSvxnzXY"},"source":["# Regresion Lineal"]},{"cell_type":"code","metadata":{"id":"6dMDzCc_kE-j"},"source":["# cargamos las librerias\n","from sklearn import datasets\n","import matplotlib.pyplot as plt\n","# cargamos el dataset\n","boston = datasets.load_boston()\n","# creamos una matriz de caracteristicas\n","X = boston.data\n","# target vector\n","y = boston.target\n","# Primera observacion\n","X[0]\n","# Mostramos como floats los elementos\n","['{:f}'.format(x) for x in X[0]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zqyHMKLMkjIi"},"source":["Primero recordar que una regresión lineal se puede implementar con\n","scipy,numpy,statsmodel o Scikit-Learn. Por ejemplo haciendo uso\n","solo de numpy obtendríamos el siguiente código :"]},{"cell_type":"code","metadata":{"id":"x-iF8DzAklOY"},"source":["from numpy import arange,array,ones,linalg\n","from pylab import plot,show\n","xi = arange(0,9)\n","A = array([ xi, ones(9)])\n","# secuencia generada\n","y = [19, 20, 20.5, 21.5, 22, 23, 23, 25.5, 24]\n","w = linalg.lstsq(A.T,y)[0] # obtencion de parametros\n","# graficando la linea\n","line = w[0]*xi+w[1] # linea de regresion\n","plt.plot(xi,line,'r-',xi,y,'o')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hRKdcJWPkx7o"},"source":["Ahora veamos el codigo usando scipy:"]},{"cell_type":"code","metadata":{"id":"qwLxIpRgk0M9"},"source":["from numpy import arange,array,ones\n","from scipy import stats\n","xi = arange(0,9)\n","A = array([ xi, ones(9)])\n","# secuencia generada\n","y = [19, 20, 20.5, 21.5, 22, 23, 23, 25.5, 24]\n","\n","slope, intercept, r_value, p_value, std_err = stats.linregress(xi,y)\n","\n","print('r value', r_value)\n","print('p_value', p_value)\n","print('standard deviation', std_err)\n","\n","line = slope*xi+intercept\n","plt.plot(xi,line,'r-',xi,y,'o')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G0ZKJHXglHdl"},"source":["Ahora veamos el codigo usando statsmmodels:"]},{"cell_type":"code","metadata":{"id":"QJ7GhLWRlG5K"},"source":["import numpy as np\n","import statsmodels.api as sm\n","\n","y = [1,2,3,4,3,4,5,4,5,5,4,5,4,5,4,5,6,5,4,5,4,3,4]\n","\n","x = [\n","[4,2,3,4,5,4,5,6,7,4,8,9,8,8,6,6,5,5,5,5,5,5,5],\n","[4,1,2,3,4,5,6,7,5,8,7,8,7,8,7,8,7,7,7,7,7,6,5],\n","[4,1,2,5,6,7,8,9,7,8,7,8,7,7,7,7,7,7,6,6,4,4,4]\n","]\n","def reg_m(y, x):\n","  ones = np.ones(len(x[0]))\n","  X = sm.add_constant(np.column_stack((x[0], ones)))\n","  for ele in x[1:]:\n","    X = sm.add_constant(np.column_stack((ele, X)))\n","  results = sm.OLS(y, X).fit()\n","  return results\n","\n","print(reg_m(y, x).summary())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ma6wBoD_lqq_"},"source":["Regresion Lineal con el Dataset Boston Housing\n","El Boston Housing Dataset consiste en el precio de las casas en\n","varios lugares en Boston. Junto con el precio, el conjunto de datos\n","también proporciona información como el crimen (CRIM), áreas de\n","negocios no minoristas en la ciudad (INDUS), la edad de las\n","personas que poseen la casa (AGE), y hay muchos otros atributos\n","disponibles.\n","\n","https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.names\n","\n","El dataset en sí está disponible en linea. Sin embargo, como vamos\n","a usar scikit-learn, podemos importarlo directamente desde\n","scikit-learn, ademas usaremos otros modulos de python."]},{"cell_type":"code","metadata":{"id":"GcRkoVVhl2PC"},"source":["import numpy as np\n","import pandas as pd\n","import scipy.stats as stats\n","import matplotlib.pyplot as plt\n","import sklearn.model_selection\n","import statsmodels.api as sm\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1dIKIUcSmR7Y"},"source":["Exploremos un poco el dataset,en primer lugar, al igual que lo que\n","hacemos con cualquier otro conjunto de datos, vamos a importar el\n","dataset Boston Housing y almacenarlo en una variable llamada\n","boston. Para importarlo de scikit-learn tendremos que ejecutar este\n","fragmento de código"]},{"cell_type":"code","metadata":{"id":"ppCq8tzwmTj1"},"source":["from sklearn.datasets import load_boston\n","boston = load_boston()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d8lAXvt3mVKy"},"source":["La variable boston es un diccionario, por ello veamos sus llaves :"]},{"cell_type":"code","metadata":{"id":"UPRs3ZTPmWiw"},"source":["print(boston.keys())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WZYboOwDmaD2"},"source":["Veamos la dimencion de la data en el dataset,asi como otras\n","propiedades :"]},{"cell_type":"code","metadata":{"id":"sPUUNLwvmaiQ"},"source":["print(boston.data.shape)\n","print(boston.feature_names)\n","print(boston.DESCR)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uLrp3RjYmfcU"},"source":["Ahora convirtamos la data del dataset en un DataFrame de pandas."]},{"cell_type":"code","metadata":{"id":"_7vSrzQAmexA"},"source":["bos = pd.DataFrame(boston.data)\n","print(bos.head())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UrMUnCt7mlZV"},"source":["Ojo con los nombres de cada una de las columnas. Utilicemos el\n","campo features_names del dataset boston original."]},{"cell_type":"code","metadata":{"id":"_2ZMtOxummyO"},"source":["bos.columns = boston.feature_names\n","print(bos.head())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NfSdOdf6mq6V"},"source":["OJO, ¿Alguien se da cuenta de que no hay una columna llamada\n","’PRECIO’ en el dataset?\n","\n","Sí, es porque la columna target está disponible en otro atributo\n","llamado target. Así que vamos a verificar el shape del\n","boston.target."]},{"cell_type":"code","metadata":{"id":"HjR6qE1RmtnQ"},"source":["print(boston.target.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jdkdY7GYmv54"},"source":["Entonces, como resulta que coincide con el número de filas del\n","dataset. Vamos a agregarlo al DataFrame como una nueva columna"]},{"cell_type":"code","metadata":{"id":"5OfBF01cmvNd"},"source":["bos['PRICE'] = boston.target\n","print(bos.head())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IgHceKMXm38Y"},"source":["Con la data ya preparada (o pre-procesada) podemos empezar con\n","el resumen estadístico"]},{"cell_type":"code","metadata":{"id":"S-X0dQrIm3nl"},"source":["print(bos.describe())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ras_pjtRm8fC"},"source":["El siguiente paso es partir (split) la data a estudiar (DataFrame) ,\n","inicialmente, en dos conjuntos: Train y Test. A diferencia del\n","dataset titanic, en boston solo tenemos un solo conjunto de\n","datos. No hay datos de entrenamiento (Train) y Testeo (Test). Así\n","que hay que hacer esta discretización nosotros mismos.\n","Básicamente antes de dividir los datos en los conjuntos\n","train-test, tendríamos que dividir el conjunto de datos en valores\n","target y valores predictor .\n","\n","Tomemos\n","Y = Precios de las casas en Boston.\n","X = Las otras características."]},{"cell_type":"code","metadata":{"id":"dHddVf6km_A8"},"source":["X = bos.drop('PRICE', axis = 1)\n","Y = bos['PRICE']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hQxb1lefnGVl"},"source":["Ahora, finalmente podemos dividir el conjunto de datos en\n","entrenamiento (Train) y pruebas (test) con el siguiente\n","fragmento de código"]},{"cell_type":"code","metadata":{"id":"U7LsDWVsnF3r"},"source":["X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, test_size = 0.33, random_state = 5)\n","print(X_train.shape)\n","print(X_test.shape)\n","print(Y_train.shape)\n","print(Y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"es3JK8ujnSOV"},"source":["Los conjuntos de datos han sido separados (discretizados) en 66.6%\n","para entrenamiento (Train) y 33.3% para pruebas (Test).\n","\n","Ahora si ejecutemos la regresion lineal:"]},{"cell_type":"code","metadata":{"id":"K3rEgb0PnTqt"},"source":["from sklearn.linear_model import LinearRegression\n","lm = LinearRegression()\n","lm.fit(X_train, Y_train)\n","Y_pred = lm.predict(X_test)\n","\n","plt.scatter(Y_test, Y_pred)\n","plt.xlabel(\"Precios: $Y_i$\")\n","plt.ylabel(\"Prediccion de Precios: $\\hat{Y}_i$\")\n","plt.title(\"Precios Vs Precios Predichos: $Y_i$ vs $\\hat{Y}_i$\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sC38SZFIngeK"},"source":["Para terminar, veamos la información ofrecida en el error cuadrático\n","medio,\n","Para verificar el nivel de error de este primer modelo, lo podemos\n","hacer usando el Mean Squared Error. Este es un procedimiento\n","para medir el cuadrado de los errores. . Básicamente, verificará la\n","diferencia entre el valor real y el valor predicho."]},{"cell_type":"code","metadata":{"id":"R5Gr5jYwnmjF"},"source":["mse = sklearn.metrics.mean_squared_error(Y_test, Y_pred)\n","print(mse)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pWe8TOisn34W"},"source":["# Regresion Logistica\n","\n","Utilizaremos algoritmos de Machine Learning en Python para\n","resolver un problema de Regresión Logística. A partir de un\n","conjunto de datos de entrada (características), nuestra salida será\n","discreta (y no continua) por eso utilizamos Regresión Logística (y\n","no Regresión Lineal). La Regresión Logística es un Algoritmo\n","Supervisado y se utiliza para clasificación.\n","\n","Vamos a clasificar problemas con dos posibles estados “SI/NO”:\n","binario o un número finito de “etiquetas” o “clases”: múltiple.\n","Algunos Ejemplos de Regresión Logística son:\n","\n","  * Clasificar si el correo que llega es Spam o No es Spam\n","  * Dados unos resultados clínicos de un tumor clasificar en “Benigno” o “Maligno”.\n","  * El texto de un artículo a analizar es: Entretenimiento,Deportes, Política ó Ciencia\n","  * A partir de historial bancario conceder un crédito o no\n","\n","Para nuestro ejercicio usaremos un archivo [csv](https://raw.githubusercontent.com/robintux/Datasets4StackOverFlowQuestions/master/usuarios_win_mac_lin.csv) con datos de entrada a modo de\n","ejemplo para clasificar si el usuario que visita un sitio web usa como\n","sistema operativo Windows, Macintosh o Linux.\n","Nuestra información de entrada son 4 características que tomé de\n","una web que utiliza Google Analytics y son:\n","1. Duración de la visita en Segundos\n","2. Cantidad de Páginas Vistas durante la Sesión\n","3. Cantidad de Acciones del usuario (click, scroll, uso de\n","checkbox, sliders,etc)\n","4. Suma del Valor de las acciones (cada acción lleva asociada una\n","valoración de importancia)\n","\n","Como la salida es discreta, asignaremos los siguientes valores a las\n","etiquetas:\n","\n","> 0 Windows\n","\n","> 1 Macintosh\n","\n","> 2 Linux\n","\n","La muestra es pequeña: son 170 registros para poder comprender el\n","ejercicio, pero recordemos que para conseguir buenos resultados\n","siempre es mejor contar con un número abundante de datos que\n","darán mayor exactitud a las predicciones y evitarán problemas de\n","overfitting u underfitting. (Por decir algo, de mil a 5 mil registros\n","no estaría mal).\n","\n","Identificar Sistema Operativo de los usuarios\n","Para comenzar hacemos los Import necesarios con los paquetes que\n","utilizaremos en el Ejercicio.\n"]},{"cell_type":"code","metadata":{"id":"ho_xWD_6ovj5"},"source":["import pandas as pd\n","import numpy as np\n","from sklearn import linear_model\n","from sklearn import model_selection\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score\n","import matplotlib.pyplot as plt\n","import seaborn as sb"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AbzaX_yRo0om"},"source":["Leemos el archivo csv y lo asignamos mediante Pandas a la variable\n","dataframe. Mediante el método dataframe.head() vemos en\n","pantalla los 5 primeros registros."]},{"cell_type":"code","metadata":{"id":"Psf6frELo1Pm"},"source":["dataframe = pd.read_csv(\"https://raw.githubusercontent.com/robintux/Datasets4StackOverFlowQuestions/master/usuarios_win_mac_lin.csv\")\n","dataframe.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bmEpbclNo8CL"},"source":["A continuación llamamos al método dataframe.describe() que nos\n","dará algo de información estadística básica de nuestro set de datos.\n","La Media, el desvío estándar, valores mínimo y máximo de cada\n","característica."]},{"cell_type":"code","metadata":{"id":"ftxk7YvQo7Q0"},"source":["dataframe.describe()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nVP9GuQ7pCvP"},"source":["Luego analizaremos cuantos resultados tenemos de cada tipo\n","usando la función groupby "]},{"cell_type":"code","metadata":{"id":"xPqGNy06pFbI"},"source":["print(dataframe.groupby('clase').size())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3nxDH-XMpJ19"},"source":["Visualización de Datos Antes de empezar a procesar el conjunto\n","de datos, vamos a hacer unas visualizaciones que muchas veces nos\n","pueden ayudar a comprender mejor las características de la\n","información con la que trabajamos y su correlación.\n","Primero visualizamos en formato de historial los cuatro Features de\n","entrada con nombres “duración”, “páginas”,”acciones” y “valor”\n","podemos ver gráficamente entre qué valores se comprenden sus\n","mínimos y máximos y en qué intervalos concentran la mayor\n","densidad de registros."]},{"cell_type":"code","metadata":{"id":"ck-oCsIfpK_p"},"source":["dataframe.drop(['clase'],1).hist()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"87rsNtBYpRNv"},"source":["Y también podemos interrelacionar las entradas de a pares, para ver\n","como se concentran linealmente las salidas de usuarios por colores:\n","Sistema Operativo Windows en azul, Macintosh en verde y Linux\n","en rojo."]},{"cell_type":"code","metadata":{"id":"g4AybYpGpRwq"},"source":["sb.pairplot(dataframe.dropna(), hue='clase',size=4,vars=[\"duracion\", \"paginas\",\"acciones\",\"valor\"],kind='reg')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-hGvW_fPpdCN"},"source":["Creamos el Modelo de Regresión Logística Ahora cargamos las\n","variables de las 4 columnas de entrada en X excluyendo la columna\n","“clase” con el método drop(). En cambio agregamos la columna\n","“clase” en la variable y. Ejecutamos X.shape para comprobar la\n","dimensión de nuestra matriz con datos de entrada de 170 registros\n","por 4 columnas."]},{"cell_type":"code","metadata":{"id":"qJETnZUrpd80"},"source":["X = np.array(dataframe.drop(['clase'],1))\n","y = np.array(dataframe['clase'])\n","X.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C72DBlKBpfgi"},"source":["Y creamos nuestro modelo y hacemos que se ajuste (fit) a nuestro\n","conjunto de entradas X y salidas ‘y’."]},{"cell_type":"code","metadata":{"id":"CVDEslT7pg6V"},"source":["model = linear_model.LogisticRegression()\n","model.fit(X,y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3D67BlyUp6bC"},"source":["Una vez compilado nuestro modelo, le hacemos clasificar todo\n","nuestro conjunto de entradas X utilizando el método “predict(X)” y\n","revisamos algunas de sus salidas y vemos que coincide con las\n","salidas reales de nuestro archivo csv."]},{"cell_type":"code","metadata":{"id":"goYngbalp7HI"},"source":["predictions = model.predict(X)\n","print(predictions[0:5])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OiseAdyfqCUV"},"source":["Y confirmamos cuan bueno fue nuestro modelo utilizando\n","model.score() que nos devuelve la precisión media de las\n","predicciones : \n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"id":"zni8Uu2BqD8u"},"source":["model.score(X,y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UKg3ROFbqN__"},"source":["## Validación de nuestro modelo \n","\n","Una buena práctica en Machine\n","Learning es la de subdividir nuestro conjunto de datos de entrada\n","en un set de entrenamiento y otro para validar el modelo (que no se\n","utiliza durante el entrenamiento y por lo tanto la máquina\n","desconoce). Esto evitará problemas en los que nuestro algoritmo\n","pueda fallar por “sobregeneralizar” el conocimiento.\n","Para ello, subdividimos nuestros datos de entrada en forma\n","aleatoria (mezclados) utilizando 80% de registros para\n","entrenamiento y 20% para validar."]},{"cell_type":"code","metadata":{"id":"qq3oQ3ycqRwN"},"source":["validation_size = 0.20\n","seed = 7\n","X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, y, test_size=validation_size, random_state=seed)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2VGC5iTYqXFc"},"source":["Volvemos a compilar nuestro modelo de Regresión Logística pero\n","esta vez sólo con 80% de los datos de entrada y calculamos el\n","nuevo scoring que ahora nos da 74%."]},{"cell_type":"code","metadata":{"id":"swukpwoVqY6_"},"source":["name='Logistic Regression'\n","kfold = model_selection.KFold(n_splits=10, random_state=seed)\n","cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n","msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n","print(msg)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dg7LK9_FqwQK"},"source":["Y ahora hacemos las predicciones -en realidad clasificación-\n","utilizando nuestro “cross validation set”, es decir del subconjunto\n","que habíamos apartado. "]},{"cell_type":"code","metadata":{"id":"By0-vZJoqwxb"},"source":["predictions = model.predict(X_validation)\n","# aciertos\n","print(accuracy_score(Y_validation, predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k5NmaJ3Rq9Zc"},"source":["Finalmente vemos en pantalla la “matriz de confusión” donde\n","muestra cuantos resultados equivocados tuvo de cada clase (los que\n","no están en la diagonal)\n","\n","Reporte de Resultados del Modelo"]},{"cell_type":"code","metadata":{"id":"FKAVCYw2q_vx"},"source":["print(confusion_matrix(Y_validation, predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XLwe4SXtrCnK"},"source":["También podemos ver el reporte de clasificación con nuestro\n","conjunto de Validación. "]},{"cell_type":"code","metadata":{"id":"iakDj-_ErVSU"},"source":["print(classification_report(Y_validation, predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rNmdquufrh6H"},"source":["En nuestro caso vemos que se utilizaron\n","como “soporte” 18 registros windows, 6 de mac y 10 de Linux (total\n","de 34 registros). "]},{"cell_type":"markdown","metadata":{"id":"Ih9nU4lpruda"},"source":["Clasificación (o predicción) de nuevos valores \n","\n","Como último\n","ejercicio, vamos a inventar los datos de entrada de navegación de\n","un usuario ficticio que tiene estos valores:\n","Tiempo Duración: 10\n","Paginas visitadas: 3\n","Acciones al navegar: 5\n","Valoración: 9\n","\n","Lo probamos en nuestro modelo y vemos que lo clasifica como un\n","usuario tipo 2, es decir, de Linux."]},{"cell_type":"code","metadata":{"id":"5EEBgIi_rzCm"},"source":["X_new = pd.DataFrame({'duracion': [10], 'paginas': [3],'acciones': [5], 'valor': [9]})\n","model.predict(X_new)"],"execution_count":null,"outputs":[]}]}